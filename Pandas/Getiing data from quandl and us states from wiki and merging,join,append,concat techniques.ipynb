{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=quandl.get('FMAC/HPI',authtoken='YZya5Hsq6QFx8sg2V-T5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   AK         AL         AR         AZ         CA         CO  \\\n",
      "Date                                                                           \n",
      "1975-01-31  34.371830  35.695975  36.738861  28.937735  15.722312  19.603977   \n",
      "1975-02-28  34.880945  35.896770  37.098962  29.463708  15.775202  19.837138   \n",
      "1975-03-31  35.402217  36.133518  37.416398  29.959514  15.964942  20.073483   \n",
      "1975-04-30  35.944703  36.425723  37.677813  30.345148  16.275547  20.301864   \n",
      "1975-05-31  36.535272  36.695708  37.921099  30.546449  16.533017  20.495075   \n",
      "\n",
      "                   CT         DC         DE         FL  \\\n",
      "Date                                                     \n",
      "1975-01-31  24.369431  18.255987  27.264842  30.997043   \n",
      "1975-02-28  24.908036  18.382701  27.250734  32.229049   \n",
      "1975-03-31  25.313556  18.514587  27.268478  34.027506   \n",
      "1975-04-30  25.541141  18.689302  27.362673  36.218077   \n",
      "1975-05-31  25.614056  18.937116  27.561893  36.437855   \n",
      "\n",
      "                          ...                        TX         UT         VA  \\\n",
      "Date                      ...                                                   \n",
      "1975-01-31                ...                 32.602350  24.698474  27.912640   \n",
      "1975-02-28                ...                 32.944116  25.060977  28.205810   \n",
      "1975-03-31                ...                 33.542975  25.381341  28.420407   \n",
      "1975-04-30                ...                 34.402826  25.627200  28.578762   \n",
      "1975-05-31                ...                 34.649755  25.782334  28.717611   \n",
      "\n",
      "                   VT         WA         WI         WV         WY  \\\n",
      "Date                                                                \n",
      "1975-01-31  26.637620  17.484315  28.096764  41.002072  31.668794   \n",
      "1975-02-28  26.956271  17.571053  28.486170  42.040473  32.161920   \n",
      "1975-03-31  27.264731  17.689717  28.860737  43.122486  32.680525   \n",
      "1975-04-30  27.546568  17.818792  29.185048  44.239196  33.210124   \n",
      "1975-05-31  27.794738  17.933277  29.443523  45.363222  33.714128   \n",
      "\n",
      "            United States not seasonaly adjusted  \\\n",
      "Date                                               \n",
      "1975-01-31                             23.497479   \n",
      "1975-02-28                             23.648785   \n",
      "1975-03-31                             23.895294   \n",
      "1975-04-30                             24.216495   \n",
      "1975-05-31                             24.416894   \n",
      "\n",
      "            United States seasonaly adjusted  \n",
      "Date                                          \n",
      "1975-01-31                         23.471007  \n",
      "1975-02-28                         23.629873  \n",
      "1975-03-31                         23.844527  \n",
      "1975-04-30                         24.111771  \n",
      "1975-05-31                         24.261528  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print (df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 53)\n"
     ]
    }
   ],
   "source": [
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak=df['AK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "1975-01-31    34.371830\n",
      "1975-02-28    34.880945\n",
      "1975-03-31    35.402217\n",
      "1975-04-30    35.944703\n",
      "1975-05-31    36.535272\n",
      "Name: AK, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (ak.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing last two waste columns but initial method fails iloc helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:-2][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 53)\n"
     ]
    }
   ],
   "source": [
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 51)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   AK         AL         AR         AZ         CA         CO  \\\n",
      "Date                                                                           \n",
      "1975-01-31  34.371830  35.695975  36.738861  28.937735  15.722312  19.603977   \n",
      "1975-02-28  34.880945  35.896770  37.098962  29.463708  15.775202  19.837138   \n",
      "1975-03-31  35.402217  36.133518  37.416398  29.959514  15.964942  20.073483   \n",
      "1975-04-30  35.944703  36.425723  37.677813  30.345148  16.275547  20.301864   \n",
      "1975-05-31  36.535272  36.695708  37.921099  30.546449  16.533017  20.495075   \n",
      "\n",
      "                   CT         DC         DE         FL    ...             SD  \\\n",
      "Date                                                      ...                  \n",
      "1975-01-31  24.369431  18.255987  27.264842  30.997043    ...      37.722210   \n",
      "1975-02-28  24.908036  18.382701  27.250734  32.229049    ...      37.319634   \n",
      "1975-03-31  25.313556  18.514587  27.268478  34.027506    ...      36.908861   \n",
      "1975-04-30  25.541141  18.689302  27.362673  36.218077    ...      36.498238   \n",
      "1975-05-31  25.614056  18.937116  27.561893  36.437855    ...      36.121328   \n",
      "\n",
      "                   TN         TX         UT         VA         VT         WA  \\\n",
      "Date                                                                           \n",
      "1975-01-31  32.179633  32.602350  24.698474  27.912640  26.637620  17.484315   \n",
      "1975-02-28  32.218599  32.944116  25.060977  28.205810  26.956271  17.571053   \n",
      "1975-03-31  32.296539  33.542975  25.381341  28.420407  27.264731  17.689717   \n",
      "1975-04-30  32.416385  34.402826  25.627200  28.578762  27.546568  17.818792   \n",
      "1975-05-31  32.563209  34.649755  25.782334  28.717611  27.794738  17.933277   \n",
      "\n",
      "                   WI         WV         WY  \n",
      "Date                                         \n",
      "1975-01-31  28.096764  41.002072  31.668794  \n",
      "1975-02-28  28.486170  42.040473  32.161920  \n",
      "1975-03-31  28.860737  43.122486  32.680525  \n",
      "1975-04-30  29.185048  44.239196  33.210124  \n",
      "1975-05-31  29.443523  45.363222  33.714128  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "states= (df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AK' 'AL' 'AR' 'AZ' 'CA' 'CO' 'CT' 'DC' 'DE' 'FL' 'GA' 'HI' 'IA' 'ID'\n",
      " 'IL' 'IN' 'KS' 'KY' 'LA' 'MA' 'MD' 'ME' 'MI' 'MN' 'MO' 'MS' 'MT' 'NC'\n",
      " 'ND' 'NE' 'NH' 'NJ' 'NM' 'NV' 'NY' 'OH' 'OK' 'OR' 'PA' 'RI' 'SC' 'SD'\n",
      " 'TN' 'TX' 'UT' 'VA' 'VT' 'WA' 'WI' 'WV' 'WY']\n"
     ]
    }
   ],
   "source": [
    "print (states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting list of states from wiki page as read_html and check same as states list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[         0              1               2               3                  4\n",
      "0   Sl no.  Abbreviations      State Name         Capital     Became a State\n",
      "1        1             AL         Alabama      Montgomery  December 14, 1819\n",
      "2        2             AK          Alaska          Juneau    January 3, 1959\n",
      "3        3             AZ         Arizona         Phoenix  February 14, 1912\n",
      "4        4             AR        Arkansas     Little Rock      June 15, 1836\n",
      "5        5             CA      California      Sacramento  September 9, 1850\n",
      "6        6             CO        Colorado          Denver     August 1, 1876\n",
      "7        7             CT     Connecticut        Hartford    January 9, 1788\n",
      "8        8             DE        Delaware           Dover   December 7, 1787\n",
      "9        9             FL         Florida     Tallahassee      March 3, 1845\n",
      "10      10             GA         Georgia         Atlanta    January 2, 1788\n",
      "11      11             HI          Hawaii        Honolulu    August 21, 1959\n",
      "12      12             ID           Idaho           Boise       July 3, 1890\n",
      "13      13             IL        Illinois     Springfield   December 3, 1818\n",
      "14      14             IN         Indiana    Indianapolis  December 11, 1816\n",
      "15      15             IA            Iowa      Des Moines  December 28, 1846\n",
      "16      16             KS          Kansas          Topeka   January 29, 1861\n",
      "17      17             KY        Kentucky       Frankfort       June 1, 1792\n",
      "18      18             LA       Louisiana     Baton Rouge     April 30, 1812\n",
      "19      19             ME           Maine         Augusta     March 15, 1820\n",
      "20      20             MD        Maryland       Annapolis     April 28, 1788\n",
      "21      21             MA   Massachusetts          Boston   February 6, 1788\n",
      "22      22             MI        Michigan         Lansing   January 26, 1837\n",
      "23      23             MN       Minnesota      Saint Paul       May 11, 1858\n",
      "24      24             MS     Mississippi         Jackson  December 10, 1817\n",
      "25      25             MO        Missouri  Jefferson City    August 10, 1821\n",
      "26      26             MT         Montana          Helena   November 8, 1889\n",
      "27      27             NE        Nebraska         Lincoln      March 1, 1867\n",
      "28      28             NV          Nevada     Carson City   October 31, 1864\n",
      "29      29             NH   New Hampshire         Concord      June 21, 1788\n",
      "30      30             NJ      New Jersey         Trenton  December 18, 1787\n",
      "31      31             NM      New Mexico        Santa Fe    January 6, 1912\n",
      "32      32             NY        New York          Albany      July 26, 1788\n",
      "33      33             NC  North Carolina         Raleigh  November 21, 1789\n",
      "34      34             ND    North Dakota        Bismarck   November 2, 1889\n",
      "35      35             OH            Ohio        Columbus      March 1, 1803\n",
      "36      36             OK        Oklahoma   Oklahoma City  November 16, 1907\n",
      "37      37             OR          Oregon           Salem  February 14, 1859\n",
      "38      38             PA    Pennsylvania      Harrisburg  December 12, 1787\n",
      "39      39             RI    Rhode Island      Providence       May 19, 1790\n",
      "40      40             SC  South Carolina        Columbia       May 23, 1788\n",
      "41      41             SD    South Dakota          Pierre   November 2, 1889\n",
      "42      42             TN       Tennessee       Nashville       June 1, 1796\n",
      "43      43             TX           Texas          Austin  December 29, 1845\n",
      "44      44             UT            Utah  Salt Lake City    January 4, 1896\n",
      "45      45             VT         Vermont      Montpelier      March 4, 1791\n",
      "46      46             VA        Virginia        Richmond      June 25, 1788\n",
      "47      47             WA      Washington         Olympia  November 11, 1889\n",
      "48      48             WV   West Virginia      Charleston      June 20, 1863\n",
      "49      49             WI       Wisconsin         Madison       May 29, 1848\n",
      "50      50             WY         Wyoming        Cheyenne      July 10, 1890,                                              0  \\\n",
      "0  vtePolitical divisions of the United States   \n",
      "1                                       States   \n",
      "2                             Federal district   \n",
      "3                                Insular areas   \n",
      "4                             Outlying islands   \n",
      "\n",
      "                                                   1  \n",
      "0                                                NaN  \n",
      "1  Alabama Alaska Arizona Arkansas California Col...  \n",
      "2                                   Washington, D.C.  \n",
      "3  American Samoa Guam Northern Mariana Islands P...  \n",
      "4  Baker Island Howland Island Jarvis Island John...  ]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Abbreviations\n",
      "1                AL\n",
      "2                AK\n",
      "3                AZ\n",
      "4                AR\n",
      "5                CA\n",
      "6                CO\n",
      "7                CT\n",
      "8                DE\n",
      "9                FL\n",
      "10               GA\n",
      "11               HI\n",
      "12               ID\n",
      "13               IL\n",
      "14               IN\n",
      "15               IA\n",
      "16               KS\n",
      "17               KY\n",
      "18               LA\n",
      "19               ME\n",
      "20               MD\n",
      "21               MA\n",
      "22               MI\n",
      "23               MN\n",
      "24               MS\n",
      "25               MO\n",
      "26               MT\n",
      "27               NE\n",
      "28               NV\n",
      "29               NH\n",
      "30               NJ\n",
      "31               NM\n",
      "32               NY\n",
      "33               NC\n",
      "34               ND\n",
      "35               OH\n",
      "36               OK\n",
      "37               OR\n",
      "38               PA\n",
      "39               RI\n",
      "40               SC\n",
      "41               SD\n",
      "42               TN\n",
      "43               TX\n",
      "44               UT\n",
      "45               VT\n",
      "46               VA\n",
      "47               WA\n",
      "48               WV\n",
      "49               WI\n",
      "50               WY\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df2[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_=[]\n",
    "for i in df2[0][1]:\n",
    "    states_.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abbreviations', 'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n"
     ]
    }
   ],
   "source": [
    "print (states_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_=states_[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n"
     ]
    }
   ],
   "source": [
    "print(states_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']\n"
     ]
    }
   ],
   "source": [
    "print(states_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC DE\n",
      "DE FL\n",
      "FL GA\n",
      "GA HI\n",
      "HI IA\n",
      "IA ID\n",
      "ID IL\n",
      "IL IN\n",
      "IN KS\n",
      "KS KY\n",
      "KY LA\n",
      "LA MA\n",
      "MA MD\n",
      "MD ME\n",
      "ME MI\n",
      "MI MN\n",
      "MN MO\n",
      "MO MS\n",
      "MS MT\n",
      "MT NC\n",
      "NC ND\n",
      "ND NE\n",
      "NE NH\n",
      "NH NJ\n",
      "NJ NM\n",
      "NM NV\n",
      "NV NY\n",
      "NY OH\n",
      "OH OK\n",
      "OK OR\n",
      "OR PA\n",
      "PA RI\n",
      "RI SC\n",
      "SC SD\n",
      "SD TN\n",
      "TN TX\n",
      "TX UT\n",
      "UT VA\n",
      "VA VT\n",
      "VT WA\n",
      "WA WI\n",
      "WI WV\n",
      "WV WY\n"
     ]
    }
   ],
   "source": [
    "for (i,j) in zip(states, states_):\n",
    "    if i!=j:\n",
    "        print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC is extra keep check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on Concat and append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat and append are not much useful while adding columns while keeping indexes same,  they just append to the end.\n",
    "WHile adding more columns with same index merge and join will suit our purpose.\n",
    "Use concat or append to add a row or series at the end of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.DataFrame({'HPI':[80,85,88,85],\n",
    "                    'Int_rate':[2, 3, 2, 2],\n",
    "                    'US_GDP_Thousands':[50, 55, 65, 55]},\n",
    "                   index = [2001, 2002, 2003, 2004])\n",
    "\n",
    "df2 = pd.DataFrame({'HPI':[80,85,88,85],\n",
    "                    'Int_rate':[2, 3, 2, 2],\n",
    "                    'US_GDP_Thousands':[50, 55, 65, 55]},\n",
    "                   index = [2005, 2006, 2007, 2008])\n",
    "\n",
    "df3 = pd.DataFrame({'HPI':[80,85,88,85],\n",
    "                    'Int_rate':[2, 3, 2, 2],\n",
    "                    'Low_tier_HPI':[50, 52, 50, 53]},\n",
    "                   index = [2001, 2002, 2003, 2004])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HPI  Int_rate  US_GDP_Thousands\n",
      "2001   80         2                50\n",
      "2002   85         3                55\n",
      "2003   88         2                65\n",
      "2004   85         2                55\n",
      "2005   80         2                50\n",
      "2006   85         3                55\n",
      "2007   88         2                65\n",
      "2008   85         2                55\n"
     ]
    }
   ],
   "source": [
    "concat = pd.concat([df1,df2])\n",
    "print(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HPI  Int_rate  Low_tier_HPI  US_GDP_Thousands\n",
      "2001   80         2           NaN              50.0\n",
      "2002   85         3           NaN              55.0\n",
      "2003   88         2           NaN              65.0\n",
      "2004   85         2           NaN              55.0\n",
      "2005   80         2           NaN              50.0\n",
      "2006   85         3           NaN              55.0\n",
      "2007   88         2           NaN              65.0\n",
      "2008   85         2           NaN              55.0\n",
      "2001   80         2          50.0               NaN\n",
      "2002   85         3          52.0               NaN\n",
      "2003   88         2          50.0               NaN\n",
      "2004   85         2          53.0               NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "concat = pd.concat([df1,df2,df3])\n",
    "print(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is where problem occurs, 2001 2002 03 04 repeated even though indexes are same and could have been concatenated better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HPI  Int_rate  US_GDP_Thousands\n",
      "2001   80         2                50\n",
      "2002   85         3                55\n",
      "2003   88         2                65\n",
      "2004   85         2                55\n",
      "2005   80         2                50\n",
      "2006   85         3                55\n",
      "2007   88         2                65\n",
      "2008   85         2                55\n"
     ]
    }
   ],
   "source": [
    "df4 = df1.append(df2)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HPI  Int_rate  Low_tier_HPI  US_GDP_Thousands\n",
      "2001   80         2           NaN              50.0\n",
      "2002   85         3           NaN              55.0\n",
      "2003   88         2           NaN              65.0\n",
      "2004   85         2           NaN              55.0\n",
      "2001   80         2          50.0               NaN\n",
      "2002   85         3          52.0               NaN\n",
      "2003   88         2          50.0               NaN\n",
      "2004   85         2          53.0               NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "df4 = df1.append(df3)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same problem as in concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HPI  Int_rate  US_GDP_Thousands\n",
      "0   80         2                50\n",
      "1   85         3                55\n",
      "2   88         2                65\n",
      "3   85         2                55\n",
      "4   80         2                50\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([80,2,50], index=['HPI','Int_rate','US_GDP_Thousands'])\n",
    "df4 = df1.append(s, ignore_index=True)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better use of append and concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge does not preserve index while join does, Join will default do on keys, while merge doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'HPI':[80,85,88,85],\n",
    "                    'Int_rate':[2, 3, 2, 2],\n",
    "                    'US_GDP_Thousands':[50, 55, 65, 55]},\n",
    "                   index = [2001, 2002, 2003, 2004])\n",
    "\n",
    "df2 = pd.DataFrame({'HPI':[80,85,88,85],\n",
    "                    'Int_rate':[2, 3, 2, 2],\n",
    "                    'US_GDP_Thousands':[50, 55, 65, 55]},\n",
    "                   index = [2005, 2006, 2007, 2008])\n",
    "\n",
    "df3 = pd.DataFrame({'HPI':[80,85,88,85],\n",
    "                    'Unemployment':[7, 8, 9, 6],\n",
    "                    'Low_tier_HPI':[50, 52, 50, 53]},\n",
    "                   index = [2001, 2002, 2003, 2004])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HPI  Int_rate  US_GDP_Thousands  Unemployment  Low_tier_HPI\n",
      "0   80         2                50             7            50\n",
      "1   85         3                55             8            52\n",
      "2   85         3                55             6            53\n",
      "3   85         2                55             8            52\n",
      "4   85         2                55             6            53\n",
      "5   88         2                65             9            50\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(df1,df3, on='HPI'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HPI  Int_rate  US_GDP_Thousands_x  US_GDP_Thousands_y\n",
      "0   80         2                  50                  50\n",
      "1   85         3                  55                  55\n",
      "2   88         2                  65                  65\n",
      "3   85         2                  55                  55\n"
     ]
    }
   ],
   "source": [
    "print(pd.merge(df1,df2, on=['HPI','Int_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Int_rate  US_GDP_Thousands  Unemployment  Low_tier_HPI\n",
      "HPI                                                        \n",
      "80          2                50             7            50\n",
      "85          3                55             8            52\n",
      "85          3                55             6            53\n",
      "85          2                55             8            52\n",
      "85          2                55             6            53\n",
      "88          2                65             9            50\n"
     ]
    }
   ],
   "source": [
    "df1.set_index('HPI', inplace=True)\n",
    "df3.set_index('HPI', inplace=True)\n",
    "joined = df1.join(df3)\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join Preserves index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Merge possible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "                    'Int_rate':[2, 3, 2, 2],\n",
    "                    'US_GDP_Thousands':[50, 55, 65, 55],\n",
    "                    'Year':[2001, 2002, 2003, 2004]\n",
    "                    })\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "                    'Unemployment':[7, 8, 9, 6],\n",
    "                    'Low_tier_HPI':[50, 52, 50, 53],\n",
    "                    'Year':[2001, 2003, 2004, 2005]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Int_rate  US_GDP_Thousands  Year  Unemployment  Low_tier_HPI\n",
      "0         2                50  2001             7            50\n",
      "1         2                65  2003             8            52\n",
      "2         2                55  2004             9            50\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(df1,df3, on='Year')\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default is inner Join, intersection of keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Int_rate  US_GDP_Thousands  Unemployment  Low_tier_HPI\n",
      "Year                                                        \n",
      "2001         2                50             7            50\n",
      "2003         2                65             8            52\n",
      "2004         2                55             9            50\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(df1,df3, on='Year')\n",
    "merged.set_index('Year', inplace=True)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Int_rate  US_GDP_Thousands  Unemployment  Low_tier_HPI\n",
      "Year                                                        \n",
      "2001         2                50           7.0          50.0\n",
      "2002         3                55           NaN           NaN\n",
      "2003         2                65           8.0          52.0\n",
      "2004         2                55           9.0          50.0\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(df1,df3, on='Year', how='left')\n",
    "merged.set_index('Year', inplace=True)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Join here means using df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Int_rate  US_GDP_Thousands  Unemployment  Low_tier_HPI\n",
      "Year                                                        \n",
      "2001       2.0              50.0             7            50\n",
      "2003       2.0              65.0             8            52\n",
      "2004       2.0              55.0             9            50\n",
      "2005       NaN               NaN             6            53\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(df1,df3, on='Year', how='right')\n",
    "merged.set_index('Year', inplace=True)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Int_rate  US_GDP_Thousands  Unemployment  Low_tier_HPI\n",
      "Year                                                        \n",
      "2001       2.0              50.0           7.0          50.0\n",
      "2002       3.0              55.0           NaN           NaN\n",
      "2003       2.0              65.0           8.0          52.0\n",
      "2004       2.0              55.0           9.0          50.0\n",
      "2005       NaN               NaN           6.0          53.0\n"
     ]
    }
   ],
   "source": [
    "merged = pd.merge(df1,df3, on='Year', how='outer')\n",
    "merged.set_index('Year', inplace=True)\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Join works ,Join always use keys to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Int_rate  US_GDP_Thousands  Unemployment  Low_tier_HPI\n",
      "Year                                                        \n",
      "2001       2.0              50.0           7.0          50.0\n",
      "2002       3.0              55.0           NaN           NaN\n",
      "2003       2.0              65.0           8.0          52.0\n",
      "2004       2.0              55.0           9.0          50.0\n",
      "2005       NaN               NaN           6.0          53.0\n"
     ]
    }
   ],
   "source": [
    "df1.set_index('Year', inplace=True)\n",
    "df3.set_index('Year', inplace=True)\n",
    "joined = df1.join(df3, how=\"outer\")\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
